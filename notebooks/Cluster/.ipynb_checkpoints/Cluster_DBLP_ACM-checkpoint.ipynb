{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Import-dataset\" data-toc-modified-id=\"Import-dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import dataset</a></span></li><li><span><a href=\"#Sentence-embedding\" data-toc-modified-id=\"Sentence-embedding-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Sentence embedding</a></span><ul class=\"toc-item\"><li><span><a href=\"#Infersent\" data-toc-modified-id=\"Infersent-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Infersent</a></span></li></ul></li><li><span><a href=\"#Dimensionality-reduction\" data-toc-modified-id=\"Dimensionality-reduction-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dimensionality reduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#TSNE\" data-toc-modified-id=\"TSNE-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>TSNE</a></span></li></ul></li><li><span><a href=\"#Blocking\" data-toc-modified-id=\"Blocking-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Blocking</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#bilstm,-rnn_dim-2048\" data-toc-modified-id=\"bilstm,-rnn_dim-2048-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>bilstm, rnn_dim 2048</a></span></li><li><span><a href=\"#Searching\" data-toc-modified-id=\"Searching-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Searching</a></span></li></ul></li><li><span><a href=\"#Result\" data-toc-modified-id=\"Result-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Result</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from preprocessing_datasets.preprocessing_utilities import get_labels_by\n",
    "\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_datasets.preprocessing_dblp_acm import clean_dblp_acm\n",
    "table, pairs = clean_dblp_acm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic integration of environmental models f...</td>\n",
       "      <td>d. scott mackay</td>\n",
       "      <td>sigmod record</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estimation of query-result distribution and it...</td>\n",
       "      <td>viswanath poosala, yannis e. ioannidis</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incremental maintenance for non-distributive a...</td>\n",
       "      <td>themistoklis palpanas, richard sidle, hamid pi...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cost-based selection of path expression proces...</td>\n",
       "      <td>zhao-hui tang, georges gardarin, jean-robert g...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benchmarking spatial join operations with spat...</td>\n",
       "      <td>erik g. hoel, hanan samet</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>dual-buffering strategies in object bases</td>\n",
       "      <td>alfons kemper, donald kossmann</td>\n",
       "      <td>very large data bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>guest editorial</td>\n",
       "      <td>philip a. bernstein, yannis ioannidis, raghu r...</td>\n",
       "      <td>the vldb journal &amp;mdash; the international jou...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>graphdb: modeling and querying graphs in datab...</td>\n",
       "      <td>ralf hartmut g&amp;#252;ting</td>\n",
       "      <td>very large data bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4908</th>\n",
       "      <td>review of the data warehouse toolkit: the comp...</td>\n",
       "      <td>alexander a. anisimov</td>\n",
       "      <td>acm sigmod record</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4909</th>\n",
       "      <td>bulk loading into an oodb: a performance study</td>\n",
       "      <td>janet l. wiener, jeffrey f. naughton</td>\n",
       "      <td>very large data bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4910 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     semantic integration of environmental models f...   \n",
       "1     estimation of query-result distribution and it...   \n",
       "2     incremental maintenance for non-distributive a...   \n",
       "3     cost-based selection of path expression proces...   \n",
       "4     benchmarking spatial join operations with spat...   \n",
       "...                                                 ...   \n",
       "4905          dual-buffering strategies in object bases   \n",
       "4906                                    guest editorial   \n",
       "4907  graphdb: modeling and querying graphs in datab...   \n",
       "4908  review of the data warehouse toolkit: the comp...   \n",
       "4909     bulk loading into an oodb: a performance study   \n",
       "\n",
       "                                                authors  \\\n",
       "0                                       d. scott mackay   \n",
       "1                viswanath poosala, yannis e. ioannidis   \n",
       "2     themistoklis palpanas, richard sidle, hamid pi...   \n",
       "3     zhao-hui tang, georges gardarin, jean-robert g...   \n",
       "4                             erik g. hoel, hanan samet   \n",
       "...                                                 ...   \n",
       "4905                     alfons kemper, donald kossmann   \n",
       "4906  philip a. bernstein, yannis ioannidis, raghu r...   \n",
       "4907                           ralf hartmut g&#252;ting   \n",
       "4908                              alexander a. anisimov   \n",
       "4909               janet l. wiener, jeffrey f. naughton   \n",
       "\n",
       "                                                  venue  year  \n",
       "0                                         sigmod record  1999  \n",
       "1                                                  vldb  1996  \n",
       "2                                                  vldb  2002  \n",
       "3                                                  vldb  1996  \n",
       "4                                                  vldb  1995  \n",
       "...                                                 ...   ...  \n",
       "4905                              very large data bases  1994  \n",
       "4906  the vldb journal &mdash; the international jou...  2003  \n",
       "4907                              very large data bases  1994  \n",
       "4908                                 acm sigmod record   2003  \n",
       "4909                              very large data bases  1994  \n",
       "\n",
       "[4910 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infersent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 2196017\n",
      "TIME: 212.6931130886078\n"
     ]
    }
   ],
   "source": [
    "from embedding_algorithms.inferSent import set_RNN_embedding\n",
    "start = time.time()\n",
    "model_type = \"bilstm\" \n",
    "char_level = False\n",
    "model_version = 2\n",
    "rnn_dim = 2048\n",
    "verbose = 1\n",
    "set_RNN_embedding(model_type, char_level, model_version, rnn_dim, verbose)\n",
    "print(\"TIME: {0}\".format(time.time() - start))\n",
    "\n",
    "params['embedding'] = {\n",
    "    'name': 'Infersent',\n",
    "    'model_type': model_type,\n",
    "    'char_level': char_level,\n",
    "    'model_version': model_version,\n",
    "    'rnn_dim': rnn_dim,\n",
    "    'verbose': verbose\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrs: ['title', 'authors']\n"
     ]
    }
   ],
   "source": [
    "from embedding_algorithms.inferSent import RNN_embedding\n",
    "attr_list = ['title', 'authors']\n",
    "params['attr_list'] = attr_list\n",
    "embeddings_tokens = RNN_embedding(table, attr_list, model_type, char_level)\n",
    "embeddings_tokens = np.array(embeddings_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting dimension: 4096\n",
      "setting TSNE with n_components: 2 & perplexity: 40\n",
      "early_exaggeration: 12\n",
      "TSNE: 254.72564888000488\n"
     ]
    }
   ],
   "source": [
    "from dimensionality_reduction_algorithms.tsne import tsne_dim_reduction\n",
    "\n",
    "start = time.time()\n",
    "tsne_embeddings = tsne_dim_reduction(\n",
    "    embeddings_tokens, \n",
    "    num_components=2,\n",
    "    early_exaggeration=12,\n",
    "    verbose=1,\n",
    "    perplexity=40,\n",
    "    method=\"barnes_hut\")\n",
    "\n",
    "print(\"TSNE: {0}\".format(time.time() - start))\n",
    "\n",
    "params['reduction'] = {\n",
    "    'name': 'TSNE',\n",
    "    'num_components': 2,\n",
    "    'early_exaggeration': 12,\n",
    "    'verbose': 1,\n",
    "    'perplexity': 40,\n",
    "    'method': \"barnes_hut\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering with NUM_CLUSTERS = 5, distance_algorithm = <function euclidean_distance at 0x7fe82890d830>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3a872ac3cb18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkMean_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsne_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'num_clusters'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distance_algorithm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLOCKS: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis_Jin/Blocking/cluster_algorithms/kMeans_cluster.py\u001b[0m in \u001b[0;36mkMean_cluster\u001b[0;34m(embeddings, key_values)\u001b[0m\n\u001b[1;32m     19\u001b[0m     kclusterer = KMeansClusterer(\n\u001b[1;32m     20\u001b[0m         NUM_CLUSTERS, distance=distance_algorithm, avoid_empty_clusters=True, repeats=25)\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0massigned_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkclusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massign_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclusterArray_to_blockDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massigned_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/thesisEnv/lib/python3.7/site-packages/nltk/cluster/util.py\u001b[0m in \u001b[0;36mcluster\u001b[0;34m(self, vectors, assign_clusters, trace)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# call abstract method to cluster the vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_vectorspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# assign the vectors to clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/thesisEnv/lib/python3.7/site-packages/nltk/cluster/kmeans.py\u001b[0m in \u001b[0;36mcluster_vectorspace\u001b[0;34m(self, vectors, trace)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cluster_vectorspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mmeanss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/thesisEnv/lib/python3.7/site-packages/nltk/cluster/kmeans.py\u001b[0m in \u001b[0;36m_cluster_vectorspace\u001b[0;34m(self, vectors, trace)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_vectorspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                     \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/thesisEnv/lib/python3.7/site-packages/nltk/cluster/kmeans.py\u001b[0m in \u001b[0;36mclassify_vectorspace\u001b[0;34m(self, vector)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_distance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mbest_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/thesisEnv/lib/python3.7/site-packages/nltk/cluster/util.py\u001b[0m in \u001b[0;36meuclidean_distance\u001b[0;34m(u, v)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \"\"\"\n\u001b[1;32m    124\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from cluster_algorithms.kMeans_cluster import kMean_cluster\n",
    "num_clusters = 5\n",
    "\n",
    "start = time.time()\n",
    "blocks = kMean_cluster(tsne_embeddings, {'num_clusters': num_clusters, 'distance_algorithm': 'euclidean'})\n",
    "print(\"BLOCKS: {0}\".format(time.time() - start))\n",
    "\n",
    "params['blocking'] = {\n",
    "    'name': 'k_means',\n",
    "    'num_clusters': num_clusters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering with NUM_CLUSTERS = 1000, \n",
      "BLOCKS: 0.6925599575042725\n"
     ]
    }
   ],
   "source": [
    "from cluster_algorithms.birch_cluster import birch_cluster\n",
    "num_clusters = 1000\n",
    "\n",
    "start = time.time()\n",
    "blocks = birch_cluster(tsne_embeddings, {'num_clusters': num_clusters})\n",
    "print(\"BLOCKS: {0}\".format(time.time() - start))\n",
    "\n",
    "params['blocking'] = {\n",
    "    'name': 'birch_cluster',\n",
    "    'num_clusters': num_clusters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster_algorithms.DBScan_cluster import DBSCAN_cluster\n",
    "eps = 7\n",
    "min_samples = 2\n",
    "\n",
    "start = time.time()\n",
    "blocks = DBSCAN_cluster(tsne_embeddings, {'eps':eps, 'min_samples':min_samples})\n",
    "print(\"BLOCKS: {0}\".format(time.time() - start))\n",
    "\n",
    "params['blocking'] = {\n",
    "    'name': 'DBScan',\n",
    "    'eps': eps,\n",
    "    'min_samples': min_samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering with NUM_CLUSTERS = 1000, \n",
      "BLOCKS: 0.5788969993591309\n"
     ]
    }
   ],
   "source": [
    "from cluster_algorithms.hierarchy_cluster import hierarchy_cluster\n",
    "num_clusters = 1000\n",
    "start = time.time()\n",
    "blocks = hierarchy_cluster(tsne_embeddings, {'num_clusters': num_clusters})\n",
    "print(\"BLOCKS: {0}\".format(time.time() - start))\n",
    "\n",
    "params['blocking'] = {\n",
    "    'name': 'hierarchy',\n",
    "    'num_clusters': num_clusters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bilstm, rnn_dim 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RR) Reduction ratio is: 0.9990375547800934\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881606240170739\n",
      "(PQ) Pair quality - Precision is: 0.18742995085783257\n",
      "(FM) Fmeasure is: 0.3145482167402156\n",
      "\n",
      "['title', 'authors']\n",
      "{'name': 'Infersent', 'model_type': 'bilstm', 'char_level': False, 'model_version': 2, 'rnn_dim': 2048, 'verbose': 1}\n",
      "{'name': 'TSNE', 'num_components': 2, 'early_exaggeration': 12, 'verbose': 1, 'perplexity': 40, 'method': 'barnes_hut'}\n",
      "{'name': 'hierarchy', 'num_clusters': 1000}\n"
     ]
    }
   ],
   "source": [
    "from evaluation import calc_index\n",
    "calc_index(blocks,table,pairs)\n",
    "print()\n",
    "print(params['attr_list'])\n",
    "print(params['embedding'])\n",
    "print(params['reduction'])\n",
    "print(params['blocking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RR) Reduction ratio is: 0.9990299209357766\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881568897408393\n",
      "(PQ) Pair quality - Precision is: 0.18595500812590882\n",
      "(FM) Fmeasure is: 0.31246855910887533\n",
      "\n",
      "['title', 'authors']\n",
      "{'name': 'Infersent', 'model_type': 'bilstm', 'char_level': False, 'model_version': 2, 'rnn_dim': 2048, 'verbose': 1}\n",
      "{'name': 'TSNE', 'num_components': 2, 'early_exaggeration': 12, 'verbose': 1, 'perplexity': 40, 'method': 'barnes_hut'}\n",
      "{'name': 'birch_cluster', 'num_clusters': 1000}\n"
     ]
    }
   ],
   "source": [
    "from evaluation import calc_index\n",
    "calc_index(blocks,table,pairs)\n",
    "print()\n",
    "print(params['attr_list'])\n",
    "print(params['embedding'])\n",
    "print(params['reduction'])\n",
    "print(params['blocking'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering with NUM_CLUSTERS = 900, \n",
      "(RR) Reduction ratio is: 0.9989036305982735\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9880951076369988\n",
      "(PQ) Pair quality - Precision is: 0.16453492772269734\n",
      "(FM) Fmeasure is: 0.2816609444840319\n",
      "clustering with NUM_CLUSTERS = 910, \n",
      "(RR) Reduction ratio is: 0.998918234474358\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881022523575871\n",
      "(PQ) Pair quality - Precision is: 0.16675615555726012\n",
      "(FM) Fmeasure is: 0.28490924578992205\n",
      "clustering with NUM_CLUSTERS = 920, \n",
      "(RR) Reduction ratio is: 0.9989351616943649\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881105336061528\n",
      "(PQ) Pair quality - Precision is: 0.16940699758435285\n",
      "(FM) Fmeasure is: 0.28876934316264863\n",
      "clustering with NUM_CLUSTERS = 930, \n",
      "(RR) Reduction ratio is: 0.9989477741328016\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881167038560013\n",
      "(PQ) Pair quality - Precision is: 0.1714375837867676\n",
      "(FM) Fmeasure is: 0.2917141898691714\n",
      "clustering with NUM_CLUSTERS = 940, \n",
      "(RR) Reduction ratio is: 0.9989586440632962\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881220215739407\n",
      "(PQ) Pair quality - Precision is: 0.17322709163346614\n",
      "(FM) Fmeasure is: 0.29430079870041964\n",
      "clustering with NUM_CLUSTERS = 950, \n",
      "(RR) Reduction ratio is: 0.9989750734238912\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881300589297363\n",
      "(PQ) Pair quality - Precision is: 0.17600388601036268\n",
      "(FM) Fmeasure is: 0.29829857299670687\n",
      "clustering with NUM_CLUSTERS = 960, \n",
      "(RR) Reduction ratio is: 0.9989876858623278\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881362289303938\n",
      "(PQ) Pair quality - Precision is: 0.1781967213114754\n",
      "(FM) Fmeasure is: 0.30144204104270655\n",
      "clustering with NUM_CLUSTERS = 970, \n",
      "(RR) Reduction ratio is: 0.9989963154254686\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.988140450464421\n",
      "(PQ) Pair quality - Precision is: 0.179728835978836\n",
      "(FM) Fmeasure is: 0.3036312849162011\n",
      "clustering with NUM_CLUSTERS = 980, \n",
      "(RR) Reduction ratio is: 0.9990073513091006\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881458491032605\n",
      "(PQ) Pair quality - Precision is: 0.18172699155730168\n",
      "(FM) Fmeasure is: 0.3064777613307958\n",
      "clustering with NUM_CLUSTERS = 990, \n",
      "(RR) Reduction ratio is: 0.9990236147165583\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881538048821931\n",
      "(PQ) Pair quality - Precision is: 0.18475397297526983\n",
      "(FM) Fmeasure is: 0.31077121006361236\n",
      "clustering with NUM_CLUSTERS = 1000, \n",
      "(RR) Reduction ratio is: 0.9990375547800934\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881606240170739\n",
      "(PQ) Pair quality - Precision is: 0.18742995085783257\n",
      "(FM) Fmeasure is: 0.3145482167402156\n",
      "clustering with NUM_CLUSTERS = 1010, \n",
      "(RR) Reduction ratio is: 0.9990488395934314\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881661441986713\n",
      "(PQ) Pair quality - Precision is: 0.18965366832417344\n",
      "(FM) Fmeasure is: 0.3176737049755243\n",
      "clustering with NUM_CLUSTERS = 1020, \n",
      "(RR) Reduction ratio is: 0.999065849790007\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881744649415237\n",
      "(PQ) Pair quality - Precision is: 0.19310712382305917\n",
      "(FM) Fmeasure is: 0.3225040795134253\n",
      "clustering with NUM_CLUSTERS = 1030, \n",
      "(RR) Reduction ratio is: 0.9990762218610898\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881795384949281\n",
      "(PQ) Pair quality - Precision is: 0.19527530764394144\n",
      "(FM) Fmeasure is: 0.32552219809837535\n",
      "clustering with NUM_CLUSTERS = 1040, \n",
      "(RR) Reduction ratio is: 0.9990828599865826\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881827855411632\n",
      "(PQ) Pair quality - Precision is: 0.19668868180584456\n",
      "(FM) Fmeasure is: 0.3274836182872637\n",
      "clustering with NUM_CLUSTERS = 1050, \n",
      "(RR) Reduction ratio is: 0.9990948915890386\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881886707568763\n",
      "(PQ) Pair quality - Precision is: 0.1993032636596993\n",
      "(FM) Fmeasure is: 0.33109960402071276\n",
      "clustering with NUM_CLUSTERS = 1060, \n",
      "(RR) Reduction ratio is: 0.9991018616208062\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881920800904455\n",
      "(PQ) Pair quality - Precision is: 0.20084996304508498\n",
      "(FM) Fmeasure is: 0.33323114653586755\n",
      "clustering with NUM_CLUSTERS = 1070, \n",
      "(RR) Reduction ratio is: 0.9991139761998308\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9881980057796733\n",
      "(PQ) Pair quality - Precision is: 0.20359617905974903\n",
      "(FM) Fmeasure is: 0.33700201519144324\n",
      "clustering with NUM_CLUSTERS = 1080, \n",
      "(RR) Reduction ratio is: 0.9991247631537569\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9882032820171693\n",
      "(PQ) Pair quality - Precision is: 0.20610542282897232\n",
      "(FM) Fmeasure is: 0.34043219542749764\n",
      "clustering with NUM_CLUSTERS = 1090, \n",
      "(RR) Reduction ratio is: 0.9991348862951336\n",
      "(PC) Pair completeness is: 0.9775179856115108\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.988208233510747\n",
      "(PQ) Pair quality - Precision is: 0.20851716861691924\n",
      "(FM) Fmeasure is: 0.3437154150197629\n"
     ]
    }
   ],
   "source": [
    "for i in range(900,1100,10):\n",
    "    num_clusters = int(i)\n",
    "    blocks = hierarchy_cluster(tsne_embeddings, {'num_clusters': num_clusters})\n",
    "    calc_index(blocks,table,pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>: 30\n",
      "starting dimension: 4096\n",
      "setting TSNE with n_components: 2 & perplexity: 30\n",
      "early_exaggeration: 12\n",
      "clustering with NUM_CLUSTERS = 29, \n",
      "(RR) Reduction ratio is: 0.9620762294641738\n",
      "(PC) Pair completeness is: 0.875\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9164744361497591\n",
      "(PQ) Pair quality - Precision is: 0.47320220298977184\n",
      "(FM) Fmeasure is: 0.61422823178578\n",
      ">>>>>>>>>>>>>>>>>>>>: 35\n",
      "starting dimension: 4096\n",
      "setting TSNE with n_components: 2 & perplexity: 35\n",
      "early_exaggeration: 12\n",
      "clustering with NUM_CLUSTERS = 29, \n",
      "(RR) Reduction ratio is: 0.9624832162699242\n",
      "(PC) Pair completeness is: 0.87243947858473\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9152520241901533\n",
      "(PQ) Pair quality - Precision is: 0.47693580199783675\n",
      "(FM) Fmeasure is: 0.6167263153564524\n",
      ">>>>>>>>>>>>>>>>>>>>: 40\n",
      "starting dimension: 4096\n",
      "setting TSNE with n_components: 2 & perplexity: 40\n",
      "early_exaggeration: 12\n",
      "clustering with NUM_CLUSTERS = 29, \n",
      "(RR) Reduction ratio is: 0.9635884062468297\n",
      "(PC) Pair completeness is: 0.8878026070763501\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.9241443790730425\n",
      "(PQ) Pair quality - Precision is: 0.5000655565753245\n",
      "(FM) Fmeasure is: 0.6397718694959321\n",
      ">>>>>>>>>>>>>>>>>>>>: 45\n",
      "starting dimension: 4096\n",
      "setting TSNE with n_components: 2 & perplexity: 45\n",
      "early_exaggeration: 12\n",
      "clustering with NUM_CLUSTERS = 29, \n",
      "(RR) Reduction ratio is: 0.9620487787412053\n",
      "(PC) Pair completeness is: 0.8093575418994413\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.8791223398906446\n",
      "(PQ) Pair quality - Precision is: 0.4373859991194415\n",
      "(FM) Fmeasure is: 0.5678820791311094\n",
      ">>>>>>>>>>>>>>>>>>>>: 50\n",
      "starting dimension: 4096\n",
      "setting TSNE with n_components: 2 & perplexity: 50\n",
      "early_exaggeration: 12\n",
      "clustering with NUM_CLUSTERS = 29, \n",
      "(RR) Reduction ratio is: 0.9629880708706057\n",
      "(PC) Pair completeness is: 0.8118016759776536\n",
      "(RM) Reference metric (Harmonic mean RR and PC) is: 0.8809554272752776\n",
      "(PQ) Pair quality - Precision is: 0.4498403792202767\n",
      "(FM) Fmeasure is: 0.5788982259570494\n"
     ]
    }
   ],
   "source": [
    "for i in [30,35,40,45,50]:\n",
    "    print('>>>>>>>>>>>>>>>>>>>>: '+str(i))\n",
    "    tsne_embeddings = tsne_dim_reduction(\n",
    "    embeddings_tokens, \n",
    "    num_components=2,\n",
    "    early_exaggeration=12,\n",
    "    verbose=1,\n",
    "    perplexity=i,\n",
    "    method=\"barnes_hut\")\n",
    "    num_clusters = 29\n",
    "    blocks = hierarchy_cluster(tsne_embeddings, {'num_clusters': num_clusters})\n",
    "    calc_index(blocks,table,pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBLP_ACM\n",
    "# RR PC alpha\n",
    "list_embedding = [0.9873, 0.9946, 0.9909]\n",
    "\n",
    "# k_means too slow\n",
    "# attrs: ['title', 'authors']\n",
    "list_hierarchy = [0.9990, 0.9775, 0.9881] # TSNE: 254.72, BLOCKS: 0.5788, n_cluster: 1000 \n",
    "list_birch = [0.9990, 0.9775, 0.9881] # TSNE: 254.72, BLOCKS: 0.0913, n_cluster: 1000\n",
    "list_DBscan = [0.9859, 0.9464, 0.9657] # TSNE: 254.72, BLOCKS: 0.00858"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('thesisEnv': conda)",
   "language": "python",
   "name": "python37764bitthesisenvcondad61bb62be9734ae9b8ba15c07cc7706a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
